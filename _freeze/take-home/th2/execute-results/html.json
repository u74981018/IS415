{
  "hash": "f1d014e2f69ed9b028d32334faec631d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take Home 2\"\nauthor: \"Lucas Vial\"\ndate: \"Sep 23 2024\"\ndate-modified: \"Date\"\nexecute: \n  eval: true\n  echo: true\n  freeze: true\n  warning: false\n---\n\n\n# \n\n\n---\ntitle: \"Take Home 2\"\nauthor: \"Lucas Vial\"\ndate: \"13 October 2024\"\nexecute: \n  eval: true\n  echo: true\n  freeze: true\n  warning: false\n---\n\n\n# **Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level**\n\n### Packages\n\nThere are pointless packages here, however you never know when you'll need something. Import for this project include:\n\n-   `spdep` used for\n\n-   `tmap` used for visualizations\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sfdep, tidyverse, sf, tmap, lubridate, spatstat, raster, sparr, spdep)\n```\n:::\n\n\n### Drug Offenses Data Import\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrug <- read_csv(\"data/2data/thai_drug_offenses_2017_2022.csv\")\n```\n:::\n\n\n### Administrative Boundaries Import\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthai <- st_read(dsn=\"data/2data/e/tha_admbnda_adm1_rtsd_20220121.shp\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\Users\\thevi\\OneDrive\\Desktop\\IS415\\IS415\\take-home\\data\\2data\\e\\tha_admbnda_adm1_rtsd_20220121.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n\n### Relational Join\n\nDo a left join on Thai and Drug to combine the Administrative Boundaries and Drug Data. Then only select necessary columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthai_drug <- left_join(thai, drug, by = c(\"ADM1_EN\" = \"province_en\")) %>%\n  dplyr::select(1:3, 14:19)\n```\n:::\n\n\n### Data Wrangling\n\nOur data is now in theory ready to be analysed, however it won't take us long to realize that our data is too poorly optimized to work in analysis, some data wrangling will help with that. There will be a few different version of the data set here for future use.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Used to calculate weights\n# It grabs one row for each province\nthai_drug_unique <- thai_drug %>%\n  group_by(ADM1_EN) %>%\n  slice(1) %>%\n  ungroup()\n\n# Used in Morans I Test \n# Just grab 2022 data\nmorans_data <- thai_drug[thai_drug$fiscal_year == 2022, ]\nmorans_data <- morans_data[morans_data$types_of_drug_offenses %in% c(\"drug_use_cases\", \"possession_cases\", \"possession_with_intent_to_distribute_cases\", \"trafficking_cases\", \"production_cases\", \"import_cases\", \"export_cases\", \"conspiracy_cases\"), ]\nmorans_data <- morans_data[morans_data$types_of_drug_offenses == \"drug_use_cases\", ]\n\n#Phuket has zero neighbours, it had to be removed for future steps\nmorans_data <- morans_data %>%\n  filter(ADM1_EN != \"Phuket\")\n```\n:::\n\n\n## Perform global spatial autocorrelation analysis by using [sfdep methods](https://is415-gaa-tskam.netlify.app/in-class_ex/in-class_ex05/in-class_ex05-glsa).\n\n### Create a Queens Contiguity Weights Matrix\n\n`st_weights()` has three arguments\n\n-   nb: neighbour list objects\n\n-   style: W for row standardized weights, C globally standardised, U is C / n, S is variance-stabilised\n\n-   allow_zero: if true, assigns zero as lagged value to zone without neighbours\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- morans_data %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)\n```\n:::\n\n\n### Compute Moran's I\n\nCalculate the Global Moran I, the output is a tibble data.frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranI <- global_moran(wm_q$no_cases,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ I: num 0.199\n $ K: num 3.83\n```\n\n\n:::\n:::\n\n\n-   `I`: is Moran's I\n\n-   `K`: is the average number of Neighbors found\n\n### **Performing Global Moran’s I Test**\n\nThis is the thing you want to run, instead of computing the stats, you want to perform a test with them. use `global_moran_test` as shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_test(wm_q$no_cases, wm_q$nb, wm_q$wt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.7036, p-value = 0.00343\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.198502468      -0.013698630       0.006160519 \n```\n\n\n:::\n:::\n\n\nHere we can see `p-value = 0.00343`, this is good because its lower than the confidence level of 0.05.\n\n### Permutation Test\n\nMonte Carlo should be used to run the simulation. Its supported by sfdep.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set a seed for reproducibility\nset.seed(1234)\n```\n:::\n\n\nVery Similar to the other test but using `global_moran_perm` and adding the nsim, which is set to 99 for how many times its going to be run through.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_perm(wm_q$no_cases, \n                  wm_q$nb, \n                  wm_q$wt, \n                  nsim = 99)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.1985, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\nHere we can see that the Moran I is `statistic = 0.1985`, which is what we were getting in earlier tests. This means that after running the simulation 100 times you still get the same results, therefore we know that Moran I is stable.\n\n## Using the extracted data, perform local spatial autocorrelation analysis by using [sfdep methods](https://r4gdsa.netlify.app/chap10.html).\n\nHere we compute the local Moran’s I of GDPPC at county level by using the `local_moran` sfdep package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>% \n  mutate(local_moran = local_moran(\n    no_cases , nb, wt, nsim = 99),\n        .before = 1) %>%\n  unnest(local_moran)\n```\n:::\n\n\nThis creates the lisa data.frame, with lots of helpful statistics, including what region is categorized as (HIGH/HIGH, p, var…..)\n\n-   Lots of p values in this df, It’s reccomended that you stick with the same one. (Use p_ii_sim, this will make it the same as your simulation)\n\n-   With the HIGH/LOW columns, the mean and media ones are the important ones.\n\n-   Skewness can help you decide - high skew means you should pick the median\n\n### **Visualising local Morans I**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\n\n# Map 1: Local Moran I\nmap1 <- tm_shape(lisa) +\n  tm_fill(\"ii\", \n          palette = \"-RdYlBu\",  # Reverse RdYlBu color palette for contrast\n          title = \"Moran's I\") +  # Add title to legend\n  tm_borders(col = \"gray40\", lwd = 0.8, alpha = 0.6) +  # Thicker, slightly transparent borders\n  tm_layout(main.title = \"Local Moran's I\", \n            main.title.size = 1.2,  # Increase title size\n            main.title.position = \"center\",  # Center the title\n            frame = FALSE)  # Remove frame\n\n# Map 2: Significance Level\nmap2 <- tm_shape(lisa) +\n  tm_fill(\"p_ii_sim\", \n          palette = \"YlOrRd\",  # Use a sequential palette for significance\n          title = \"Significance Level\", \n          style = \"fixed\",  # Fix color breakpoints if needed\n          breaks = c(0, 0.01, 0.05, 0.1, 1),  # Significance thresholds\n          labels = c(\"<0.01\", \"0.01-0.05\", \"0.05-0.1\", \">0.1\")) +  # Label significance levels\n  tm_borders(col = \"gray40\", lwd = 0.8, alpha = 0.6) +  # Same border styling\n  tm_layout(main.title = \"Significance Level\", \n            main.title.size = 1.2, \n            main.title.position = \"center\", \n            frame = FALSE)\n\n# Arrange maps side by side\ntmap_arrange(map1, map2, ncol = 2, asp = 1, outer.margins = 0.01)  # Adjust aspect ratio and margins\n```\n\n::: {.cell-output-display}\n![](th2_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n### Lisa Map Visualisation\n\nThe LISA Map Visualization is a combination of the p significance level and local moran I, it will graph the Moran correlations when the significance meets its required level (null hypothesis)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa_sig <- lisa %>% \n  filter(p_ii < 0.05)\ntm_shape(lisa)+\n  tm_polygons()+\n  tm_borders(alpha=0.5)+\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\")+\n  tm_borders(alpha=0.4)+\n  tm_layout(main.title = \"LISA map\")\n```\n\n::: {.cell-output-display}\n![](th2_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### Hot and Cold Spot Analysis\n\nCompute Local G\\* Statistic\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_idw <- morans_data %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n```\n:::\n\n\nIn a similar way to LISA/Moran\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nHCSA <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    no_cases, nb, wt, nsim = 99),\n    .before = 1) %>%\n  unnest(local_Gi)\nHCSA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 74 features and 21 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n# A tibble: 74 × 22\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     <dbl> <fct>    <dbl>      <dbl>   <dbl>   <dbl> <dbl>        <dbl>    <dbl>\n 1 -0.355  High    0.0150 0.00000832 -0.942    0.346  0.4          0.2     0.115\n 2  0.612  High    0.0140 0.0000145   0.705    0.481  0.42         0.21    0.577\n 3  0.0231 Low     0.0117 0.0000132   0.511    0.609  0.56         0.28    0.372\n 4 -0.621  Low     0.0129 0.00000979 -0.458    0.647  0.72         0.36    0.820\n 5 -1.09   Low     0.0132 0.0000116  -0.969    0.333  0.28         0.14    0.432\n 6 -1.28   Low     0.0122 0.0000182  -1.05     0.293  0.32         0.16    0.336\n 7 -1.66   Low     0.0123 0.0000155  -1.38     0.168  0.14         0.07    0.427\n 8 -1.80   Low     0.0116 0.0000147  -1.38     0.167  0.12         0.06    0.726\n 9 -0.125  Low     0.0121 0.0000105   0.269    0.788  0.64         0.32    0.756\n10  0.639  High    0.0163 0.0000150   0.0346   0.972  0.98         0.49    0.284\n# ℹ 64 more rows\n# ℹ 13 more variables: kurtosis <dbl>, nb <nb>, wts <list>, Shape_Leng <dbl>,\n#   Shape_Area <dbl>, ADM1_EN <chr>, date <date>, validOn <date>,\n#   validTo <date>, fiscal_year <dbl>, types_of_drug_offenses <chr>,\n#   no_cases <dbl>, geometry <MULTIPOLYGON [°]>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(HCSA)+\n  tm_fill(\"gi_star\")+\n  tm_borders(alpha=0.5)+\n  tm_layout(main.title = \"G* Statistic\")\n```\n\n::: {.cell-output-display}\n![](th2_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA_sig <- HCSA %>% \n  filter(p_sim < 0.05)\n\ntm_shape(HCSA)+\n  tm_polygons()+\n  tm_borders(alpha=0.5)+\ntm_shape(HCSA_sig)+\n  tm_fill(\"gi_star\")+\n  tm_borders(alpha=0.4) + \n  tm_layout(main.title = \"G* (Significant)\")\n```\n\n::: {.cell-output-display}\n![](th2_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n# **Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level**\n\n### Packages\n\n*package summary here*\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sfdep, tidyverse, sf, tmap, lubridate, spatstat, raster, sparr)\n```\n:::\n\n\n### Drug Offenses Data Import\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrug <- read_csv(\"data/2data/thai_drug_offenses_2017_2022.csv\")\n```\n:::\n\n\n### Administrative Boundaries Import\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthai <- st_read(dsn=\"data/2data/e/tha_admbnda_adm1_rtsd_20220121.shp\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\Users\\thevi\\OneDrive\\Desktop\\IS415\\IS415\\take-home\\data\\2data\\e\\tha_admbnda_adm1_rtsd_20220121.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n\n### Relational Join\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthai <- thai %>% rename(Province = ADM1_EN)\ndrug <- drug %>% rename(Province = province_en)\n\nthai_drug <- left_join(thai, drug)\n```\n:::\n\n\n## Perform global spatial autocorrelation analysis by using [sfdep methods](https://is415-gaa-tskam.netlify.app/in-class_ex/in-class_ex05/in-class_ex05-glsa).\n",
    "supporting": [
      "th2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}